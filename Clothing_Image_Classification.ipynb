{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIEUwXJSfuIMZeVrbxhilR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/briggsrr/BST-Movie-Sorter/blob/master/Clothing_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o12d_r4njOp3",
        "outputId": "c10148a6-6b15-489c-c63d-82727c7806ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "--- \n",
        "\n",
        "<h1> Loading Packages </h1>\n"
      ],
      "metadata": {
        "id": "fury9QiGvhPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Input, InputLayer, Flatten\n",
        "from keras.models import Sequential, Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.callbacks import EarlyStopping\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm # progress bar thing\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "oFiMtAN8jeK0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Each (28 pixels*28 pixels) image can be viewed as a 28*28 2-dimensional matrix, where\n",
        "#each element in this matrix is an integer within 0~255.\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n",
        "class_names_label = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "ISIZE = (28,28)\n",
        "print(class_names_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xe1MfBYmuhn",
        "outputId": "c7bab67c-cd74-4cb9-ed1c-451cef425537"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'T-shirt/top': 0, 'Trouser': 1, 'Pullover': 2, 'Dress': 3, 'Coat': 4, 'Sandal': 5, 'Shirt': 6, 'Sneaker': 7, 'Bag': 8, 'Ankle Boot': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "<h1> Data Processing</h1>"
      ],
      "metadata": {
        "id": "O_FqIKOBvywL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load(path):\n",
        "    output = []\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    print(f\"Loading {path}\")\n",
        "\n",
        "    #iterate through each folder\n",
        "    for folder in os.listdir(path):\n",
        "        label = folder[0]\n",
        "        if(label == 1):\n",
        "          return images, labels\n",
        "\n",
        "        #iterate through each image with progress bar\n",
        "        for file in tqdm(os.listdir(os.path.join(path, folder))): \n",
        "            img_p = os.path.join(os.path.join(path, folder), file)\n",
        "\n",
        "            image = cv2.imread(img_p)\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "\n",
        "    images = np.array(images, dtype = 'float32')\n",
        "    labels = np.array(labels, dtype = 'int32') \n",
        "\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "a_-ujk9W0N7U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/hw4_train'\n",
        "test_path = '/content/drive/MyDrive/hw4_test'\n",
        "\n",
        "train_images, train_labels = load(train_path)\n",
        "test_images, test_labels = load(test_path)\n",
        "\n",
        "#normalize \n",
        "train_images = train_images / 255.0 \n",
        "#test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "FZl4y1GK0Wie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- \n",
        "<h1> Testing Data </h1>"
      ],
      "metadata": {
        "id": "4Gk9OiglI1fB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[1])\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OrS4e4ODJHQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "<h1> Feature Extraction </h1>\n"
      ],
      "metadata": {
        "id": "67NAJdL0BPVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fmodel = VGG16(weights='imagenet', include_top=False)\n",
        "train_features = fmodel.predict(train_images)\n",
        "test_features = fmodel.predict(test_images)\n",
        "\n",
        "n_train, x, y, z = train_features.shape\n",
        "n_test, x, y, z = test_features.shape"
      ],
      "metadata": {
        "id": "Hf8vguGbBVJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<h1> Employing Model Ensembles Bagging</h1>"
      ],
      "metadata": {
        "id": "N_0jEHcT4OR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_count = 5\n",
        "max_samples = 0.8 # Proporition of samples to use to train for each model\n",
        "max_samples *= n_train\n",
        "max_samples = int(max_samples)\n",
        "\n",
        "models = []\n",
        "histories =[]\n",
        "\n",
        "for _ in range(model_count):\n",
        "    model = keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(filters=64, kernel_size=(7, 7), input_shape=(x,y,z), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n",
        "      tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n",
        "      tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dropout(.5),\n",
        "      tf.keras.layers.Dense(units=9, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'], callbacks=[EarlyStopping(monitor='val_loss', patience=3)])\n",
        "    models.append(model)"
      ],
      "metadata": {
        "id": "xBzf8fiHv394"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bagging\n",
        "for i in range(model_count):\n",
        "    train_idx = np.random.choice(len(train_features), size = max_samples)\n",
        "    histories.append(models[i].fit(train_features[train_idx], train_labels[train_idx], batch_size=128, epochs=20, validation_split = 0.2))"
      ],
      "metadata": {
        "id": "OCVcBH4dLv3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#aggregating \n",
        "predictions = []\n",
        "for i in range(model_count):\n",
        "    prediction = models[i].predict(test_features)\n",
        "    predictions.append(prediction)\n",
        "\n",
        "predictions = np.array(predictions)\n",
        "predictions = predictions.sum(axis = 0)\n",
        "pred_labels = predictions.argmax(axis=1)\n",
        "\n",
        "print(\"Accuracy : {}\".format(accuracy_score(test_labels, pred_labels)))"
      ],
      "metadata": {
        "id": "V0oxWi66LzXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-S5Kc-_o76dd"
      }
    }
  ]
}